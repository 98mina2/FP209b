{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4150e87",
   "metadata": {},
   "source": [
    "# Restaurant Recommender System\n",
    "\n",
    "**Authors**: Lyla Kiratiwudhikul, Mina Lee, Tom Zhang"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5969f1a4",
   "metadata": {},
   "source": [
    "## Motivations and Objectives\n",
    "\n",
    "For the past few decades, with the fast growing market of digital platforms, \n",
    "companies have tried to customize the advertising of their products based on individual customers' preferences or interests. \n",
    "This practice has been utilized across various industries and companies, from the e-commerce site Amazon suggesting relevant products to the streaming platform Netflix recommending similar shows to their users' view history and profile. The recommendation systems help increase sales as the users are able to easily see and purchase recommended products that match their needs and preferences.\n",
    "\n",
    "In this project, we focus on devising a restaurant recommendation system (hereby referred to as “recommender”).\n",
    "We use data of restaurants and customer profiles from Yelp, a platform for crowd-sourced reviews about businesses.\n",
    "As an individual has unique restaurant preferences, such as cuisines, ambience, pets, diet types, and/or parking availability, we aim to build the recommender to recommend restaurants to users based on the insights gleaned from their reviews on the previous restaurants they have been to."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a83c8336",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "The data is downloaded from [Yelp official website](https://www.yelp.com/dataset/documentation/main). There are two datasets relevant to our analysis and models: `business` and `review` data. The `business` dataset contains information about the businesses including name, location, hours, average rating stars, hours, number of reviews, and other features such as cuisine types and parking availability. The `review` dataset records full review text data as well as the `user_id` who wrote the review and the `business_id` for which the review was written. There are 150,346 businesses and 6,990,280 reviews in the Yelp original datasets. Below is the list of features in the two raw datasets:\n",
    "\n",
    "**Business:**\n",
    "- `business_id`: business’s ID, string\n",
    "- `name`: business’s name, string\n",
    "- `address`: business’s full address, string\n",
    "- `city`: business’s city, string\n",
    "- `state`: business’s state, string, 2 character state code, if applicable\n",
    "- `postal_code`: business’s postal code, string\n",
    "- `latitude`: business’s latitude, float\n",
    "- `longitude`: business’s longitude, float\n",
    "- `stars`: business’s average stars rating, float (1 to 5)\n",
    "- `review_count`: business’s number of reviews, integer\n",
    "- `is_open`\t: whether the business is open or closed; 0 or 1 for closed or open, integer\n",
    "- `attributes`: business’s features (e.g whether it offers parking, whether it accept credit cards, etc), JSON object\n",
    "- `categories`: business’s categories (e.g. “Mexican”, “Burger”, etc), array of strings\n",
    "- `hours`: business’s working hours, object of key day (Monday-Sunday) to value hours\n",
    "\n",
    "**Review:**\n",
    "- `review_id`: unique review ID, string\n",
    "- `user_id`: 22 character user’s ID, string\n",
    "- `business_id`: 22 character business’s ID, string\n",
    "- `stars`: business’s stars rating, integer (1 to 5)\n",
    "- `useful`: number of useful votes received, integer\n",
    "- `integer`: number of funny votes received, integer\n",
    "- `cool`: number of cool votes received, integer\t\n",
    "- `text`: review itself, string\n",
    "- `date`: date format YYYY-MM-DD, string\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ef6722d",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "**Business:**\n",
    "\n",
    "As the main goal of this project is to build a recommender system that suggests top restaurants and their offerings based on user location, we have excluded the entries that are not classified as restaurants such as “spas”, “hotels”, and “hair salons” by dropping all rows whose `categories` do not contain any of the following keywords: “food”, “restaurant”, “bar”, “pubs”, “restaurant”, “tea”, and “coffee”. This has decreased the number of entries from 150,346 to 69,253.\n",
    "\n",
    "Further, we have expanded `attributes` columns based on the JSON objects given. The first attempt returned 39 new columns. However, some of the expanded features contained nested JSON objects, so we further expanded `BusinessParking`, `Ambience`, `DietaryRestrictons`, and `Music` features and concatenated them to the other attributes, resulting in final 62 columns.\n",
    "\n",
    "In addition, the missing values in original and newly created attributes based features are filled with `None`, indicating that the information is not available. We decided to impute the missing values this way instead of mode imputation method because there are users who might be indifferent regarding the missing attributes and those who are concerned about them (e.g. whether there is parking or not).\n",
    "\n",
    "For `hours`, an expansion of operating hour objects into seven days was performed first. For the 9,710 missing entries for hours, we imputed the operating hours with the modes of the dataset for businesses whose value for the hours column was completely missing and imputed with `\"closed\"` for businesses whose hours are available for only some days and are not provided for the other days (i.e. we assumed that these restaurants are closed on the missing days).\n",
    "\n",
    "Furthermore, there are a few states that have only one business in our dataset, which are not suitable for our recommender task, and we have, thus, decided to drop these states with only one business: North Carolina, Colorado, Hawaii, Montana, and South Dakota.\n",
    "\n",
    "The final dataset for the business records has a total of 84 features with 68,054 entries. The business dataset has a total of five numeric features (`latitude`, `longitude`, `stars`, `review_count`, `is_open`). However, since `is_open` is a binary feature and `latitude` and `longitude` are useful in their original states. Only `stars` and `review_count` have been standardized to prevent any potential bias from large scales.\n",
    "\n",
    "\n",
    "**Review:**\n",
    "\n",
    "For the review dataset, we have first filtered the dataset in accordance with the business dataset by filtering out reviews for irrelevant businesses (using `business_id`) that have been pre-processed out as described above. This has reduced the size of the review dataset from 6,990,280 to 5,257,329 entries. Since the review dataset do not have missing entries, no imputation or dropping related to missing values have been conducted. However, we have decided to standardize the numeric features (`stars`, `useful`, `funny`, `cool`) in the review dataset to prevent any larger scales dominating the analysis and leading to a biased result.\n",
    "\n",
    "Note: the code for data preparation can be found in `business_dat_inspect.ipynb` and `review_data_inspect.ipynb`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0592271",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "TODO:\n",
    "\n",
    "In terms of the balance of the dataset, there is an imbalance since some restaurants have received much larger quantities of reviews than others. However, mitigating class imbalance in this dataset can be considered improper since the number of reviews could be an indicator for the business’s popularity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "064d949a-394c-4a65-b9cf-3c1f3f8805c4",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e10231c8-2f41-4665-9d31-64116d27f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# pip install scikit-surprise\n",
    "from surprise import Dataset, Reader, KNNWithMeans\n",
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18be3da-4c7d-4323-81a4-18767b5034cf",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8252c922-5264-4bdb-8773-0f708230272d",
   "metadata": {},
   "source": [
    "There are multiple ways to implement a recommendation system:\n",
    "\n",
    "- collaborative filtering\n",
    "- content-based filtering\n",
    "- hybrid\n",
    "\n",
    "In particular, collaborative filtering can be further divided into two types (a hyper-parameter):\n",
    "\n",
    "- user-based: find similar users based on ratings a user gave out\n",
    "- item-based: find similar items based on ratings given to an item\n",
    "\n",
    "In either case, the algorithm relies on a user-item matrix, in which the rows match the users and columns the items. From here, we can then make predictions after calculating similarities amongst the users or items. This is known as a memory-based approach. If we apply an extra step to reduce the sparse user-item matrix with matrix factorization, this would be called a model-based approach.\n",
    "\n",
    "For our baseline model, we will implement the memory-based collaborative filtering technique.\n",
    "\n",
    "We also need to install `scikit-surprise`, a recommendation system package: `pip install scikit-surprise`. One of its functions `KNNWithMeans` would be particularly useful here. It is a basic collaborative filtering algorithm, taking into account the mean ratings of each user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a41a5b7-c665-49ec-8a8a-7cd9d84d9619",
   "metadata": {},
   "source": [
    "## Prep Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da69063c-268a-4cd3-8e52-ddfbc06686cf",
   "metadata": {},
   "source": [
    "We require a data frame with 3 columns: user, item, rating; with each row corresponding to a user's rating for a particular restaurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "956d588e-0302-483b-ae84-e8983bd9ec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.read_feather('data/yelp_review_cleaned.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58959566-d452-4fac-80d2-8cbdb9394d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = review_df.loc[:, ['user_id', 'business_id', 'stars']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caf13ff-b70f-4bff-91c7-117fac56da49",
   "metadata": {},
   "source": [
    "Note that we previously scaled `stars`, so we will now un-scale it as we're now using it as our response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40fe39f5-4ab5-41d2-b6ef-ca658eea0c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "stars_scaled_unique = sorted(list(df['stars'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91d465f4-d1c0-42fb-a26f-65abe81963b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-2.0123613662910693: 1,\n",
       " -1.2947376560318022: 2,\n",
       " -0.5771139457725354: 3,\n",
       " 0.1405097644867315: 4,\n",
       " 0.8581334747459984: 5}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars_scale_map = dict(list(zip(stars_scaled_unique, range(1, 6))))\n",
    "stars_scale_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1690f452-3d40-4c98-ab50-3ce39ec3b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stars'] = df['stars'].map(stars_scale_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9b5bbf1-ae65-4d7d-8906-dfd629cd10c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 4, 1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stars.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2cb1e2-e05a-489b-8c00-9fe90b7a14f7",
   "metadata": {},
   "source": [
    "We will take a smaller random sample out of concerns for the hardware:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "959c9c23-ad08-4341-ba6e-fae55e10414c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5257329, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14e00028-ac4d-41e0-8c67-296bb431a187",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = df.sample(10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ce94772-92bc-4b8b-9e8b-44343645c61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1322294</th>\n",
       "      <td>0lpxU4Dfi8AeBt0SeCrEuw</td>\n",
       "      <td>tQKqrLs16Xi-lFrd3_CBAQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4297632</th>\n",
       "      <td>5nw1Zc3fi_ehDJFd3mUEYA</td>\n",
       "      <td>nLxNJuvgoHQHn_IGYifRnw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143059</th>\n",
       "      <td>7fDqaGdUMccXQ4bnPwR6yg</td>\n",
       "      <td>etaIhl-sduOKc6J_qHmmtA</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3068250</th>\n",
       "      <td>GyFJNSJjI5aWww-D0Btcbw</td>\n",
       "      <td>GlKffg2PMtzByocI5OHIQA</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371839</th>\n",
       "      <td>o66iBwIWxfWPypnqfrHVNw</td>\n",
       "      <td>XVFUNtPWYpxhoWPtBQHFdQ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user_id             business_id  stars\n",
       "1322294  0lpxU4Dfi8AeBt0SeCrEuw  tQKqrLs16Xi-lFrd3_CBAQ      1\n",
       "4297632  5nw1Zc3fi_ehDJFd3mUEYA  nLxNJuvgoHQHn_IGYifRnw      1\n",
       "2143059  7fDqaGdUMccXQ4bnPwR6yg  etaIhl-sduOKc6J_qHmmtA      3\n",
       "3068250  GyFJNSJjI5aWww-D0Btcbw  GlKffg2PMtzByocI5OHIQA      3\n",
       "1371839  o66iBwIWxfWPypnqfrHVNw  XVFUNtPWYpxhoWPtBQHFdQ      2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92799140-a065-4cb4-8f4f-2557adbf6bee",
   "metadata": {},
   "source": [
    "## Build Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba377d19-2502-490b-b456-d967de6150dd",
   "metadata": {},
   "source": [
    "Test: Collaborative filtering (item-based matrix, memory-based method, cosine-similarity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12bb5d35-fa5d-465e-9ce9-0a304aab4071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data into scikit-surprise format\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(sub, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96c9ba4b-8fce-4c55-945e-85040e25da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "sim_options = {\n",
    "    \"name\": \"cosine\",  # to use item-based cosine similarity\n",
    "    \"user_based\": False,  # Compute similarities between items\n",
    "}\n",
    "\n",
    "algo = KNNWithMeans(sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b634980-3ffe-42bd-94fa-1f0cf80e36d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7a7dcd0-7698-411c-b202-68d2e39af8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x3baeb9cc0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.fit(trainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cc8fe84-78cd-4c5a-bfd5-885fc0a74c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = algo.predict(sub.iloc[4, 0], sub.iloc[4, 1])\n",
    "prediction.est"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c356da20-c298-405a-894f-fa895d1d35ce",
   "metadata": {},
   "source": [
    "Now incorporate hyper-parameter tuning with grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36420f5c-5f15-496f-8862-981f78877f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {\n",
    "    \"name\": [\"msd\", \"cosine\"],\n",
    "    \"min_support\": [3, 4, 5],\n",
    "    \"user_based\": [False, True],\n",
    "}\n",
    "\n",
    "param_grid = {\"sim_options\": sim_options}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f63ed71-b730-4bb2-8fb7-8a7ce08f3451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(KNNWithMeans, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "gs.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e68e3dcd-bb6f-46cd-bda8-d599fea6b715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best rmse: 1.4087381876138967\n",
      "best params: {'sim_options': {'name': 'msd', 'min_support': 3, 'user_based': True}}\n"
     ]
    }
   ],
   "source": [
    "print(f'best rmse: {gs.best_score[\"rmse\"]}')\n",
    "print(f'best params: {gs.best_params[\"rmse\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0b7b22-6e49-4189-b48e-da7d3f9d6ab6",
   "metadata": {},
   "source": [
    "## Up Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87455c07-c7ad-49c1-ba46-42a0f7188686",
   "metadata": {},
   "source": [
    "- Test model-based approach in collaborative filtering\n",
    "- Test content-based recommenders\n",
    "- Use more complex models such as neural networks rather than just cosine similarities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
